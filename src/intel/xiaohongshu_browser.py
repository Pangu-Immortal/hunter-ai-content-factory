"""
Hunter AI å†…å®¹å·¥å‚ - å°çº¢ä¹¦æµè§ˆå™¨é‡‡é›†æ¨¡å—

åŠŸèƒ½ï¼š
- åŸºäº Playwright æµè§ˆå™¨è‡ªåŠ¨åŒ–é‡‡é›†å°çº¢ä¹¦ç¬”è®°
- ç»•è¿‡ X-s ç­¾åéªŒè¯é—®é¢˜
- æ”¯æŒ Cookie æ³¨å…¥ç™»å½•

ä½¿ç”¨æ–¹æ³•ï¼š
    from src.intel.xiaohongshu_browser import XiaohongshuBrowser

    browser = XiaohongshuBrowser()
    notes = await browser.search("AIå·¥å…·")

GitHub: https://github.com/Pangu-Immortal/hunter-ai-content-factory
Author: Pangu-Immortal
"""

import asyncio
import json
import re
import random
from pathlib import Path
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional

from src.config import settings, ROOT_DIR
from src.utils.logger import get_logger
from src.utils.ai_client import get_ai_client
from src.intel.utils import create_article_dir, get_article_file_path, get_today_str

logger = get_logger("hunter.intel.xiaohongshu_browser")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ•°æ®æ¨¡å‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class XhsNote:
    """å°çº¢ä¹¦ç¬”è®°æ•°æ®"""
    note_id: str                          # ç¬”è®° ID
    title: str                            # æ ‡é¢˜
    desc: str                             # æè¿°/æ­£æ–‡
    author: str                           # ä½œè€…æ˜µç§°
    author_id: str = ""                   # ä½œè€… ID
    likes: int = 0                        # ç‚¹èµæ•°
    collects: int = 0                     # æ”¶è—æ•°
    comments: int = 0                     # è¯„è®ºæ•°
    images: list[str] = field(default_factory=list)  # å›¾ç‰‡åˆ—è¡¨
    tags: list[str] = field(default_factory=list)    # æ ‡ç­¾åˆ—è¡¨
    url: str = ""                         # ç¬”è®°é“¾æ¥
    created_at: Optional[datetime] = None # å‘å¸ƒæ—¶é—´

    def to_dict(self) -> dict:
        """è½¬ä¸ºå­—å…¸"""
        return {
            "note_id": self.note_id,
            "title": self.title,
            "desc": self.desc,
            "author": self.author,
            "author_id": self.author_id,
            "likes": self.likes,
            "collects": self.collects,
            "comments": self.comments,
            "images": self.images,
            "tags": self.tags,
            "url": self.url,
            "created_at": self.created_at.isoformat() if self.created_at else None,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å°çº¢ä¹¦æµè§ˆå™¨é‡‡é›†å™¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class XiaohongshuBrowser:
    """
    å°çº¢ä¹¦æµè§ˆå™¨é‡‡é›†å™¨ - åŸºäº Playwright

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æµè§ˆå™¨æ¨¡æ‹Ÿ - ç»•è¿‡åçˆ¬éªŒè¯
    2. Cookie æ³¨å…¥ - å®ç°ç™»å½•æ€
    3. é¡µé¢è§£æ - æå–ç¬”è®°å†…å®¹
    """

    BASE_URL = "https://www.xiaohongshu.com"

    def __init__(self):
        """åˆå§‹åŒ–é‡‡é›†å™¨"""
        self.cookies = self._load_cookies()
        self.browser = None
        self.context = None
        self.page = None

    def _load_cookies(self) -> list[dict]:
        """
        åŠ è½½ Cookie å¹¶è½¬æ¢ä¸º Playwright æ ¼å¼

        Returns:
            Playwright æ ¼å¼çš„ cookies åˆ—è¡¨
        """
        # ä»é…ç½®æ–‡ä»¶åŠ è½½
        if hasattr(settings, 'xiaohongshu') and settings.xiaohongshu.cookies:
            cookie_str = settings.xiaohongshu.cookies
            return self._parse_cookie_string(cookie_str)

        return []

    def _parse_cookie_string(self, cookie_str: str) -> list[dict]:
        """
        è§£æ Cookie å­—ç¬¦ä¸²ä¸º Playwright æ ¼å¼

        Args:
            cookie_str: å¦‚ "a1=xxx; web_session=xxx"

        Returns:
            Playwright cookies åˆ—è¡¨
        """
        cookies = []
        for item in cookie_str.split(';'):
            item = item.strip()
            if '=' in item:
                key, value = item.split('=', 1)
                cookies.append({
                    "name": key.strip(),
                    "value": value.strip(),
                    "domain": ".xiaohongshu.com",
                    "path": "/",
                })
        return cookies

    def is_logged_in(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²é…ç½® Cookie"""
        cookie_names = [c["name"] for c in self.cookies]
        required = ['web_session', 'a1']
        return all(name in cookie_names for name in required)

    async def _init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        from playwright.async_api import async_playwright

        logger.info("æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")

        self._playwright = await async_playwright().start()

        # å¯åŠ¨æµè§ˆå™¨ï¼ˆæ— å¤´æ¨¡å¼ï¼‰
        self.browser = await self._playwright.chromium.launch(
            headless=True,  # æ— å¤´æ¨¡å¼
            args=[
                '--disable-blink-features=AutomationControlled',  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
                '--no-sandbox',
                '--disable-setuid-sandbox',
            ]
        )

        # åˆ›å»ºä¸Šä¸‹æ–‡ï¼ˆæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ï¼‰
        self.context = await self.browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            locale='zh-CN',
            timezone_id='Asia/Shanghai',
        )

        # æ³¨å…¥ Cookie
        if self.cookies:
            await self.context.add_cookies(self.cookies)
            logger.info(f"å·²æ³¨å…¥ {len(self.cookies)} ä¸ª Cookie")

        # åˆ›å»ºé¡µé¢
        self.page = await self.context.new_page()

        # éšè— WebDriver ç‰¹å¾
        await self.page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
            window.chrome = { runtime: {} };
        """)

        logger.info("æµè§ˆå™¨å¯åŠ¨å®Œæˆ")

    async def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.browser:
            await self.browser.close()
            self.browser = None
        if hasattr(self, '_playwright') and self._playwright:
            await self._playwright.stop()
            self._playwright = None
        logger.info("æµè§ˆå™¨å·²å…³é—­")

    async def search(
        self,
        keyword: str,
        count: int = 10,
        sort: str = "popularity_descending",  # general, time_descending, popularity_descending
    ) -> list[XhsNote]:
        """
        æœç´¢å°çº¢ä¹¦ç¬”è®°

        Args:
            keyword: æœç´¢å…³é”®è¯
            count: è·å–æ•°é‡
            sort: æ’åºæ–¹å¼

        Returns:
            ç¬”è®°åˆ—è¡¨
        """
        if not self.page:
            await self._init_browser()

        logger.info(f"æœç´¢å…³é”®è¯: {keyword}")

        try:
            # è®¿é—®æœç´¢é¡µ
            search_url = f"{self.BASE_URL}/search_result?keyword={keyword}&source=web_search_result_notes"
            await self.page.goto(search_url, wait_until='networkidle', timeout=30000)

            # ç­‰å¾…é¡µé¢åŠ è½½
            await asyncio.sleep(2)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
            page_content = await self.page.content()
            if 'ç™»å½•' in page_content and 'æ³¨å†Œ' in page_content and len(page_content) < 5000:
                logger.warning("æ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼ŒCookie å¯èƒ½å·²è¿‡æœŸ")
                return []

            # æ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹
            for _ in range(3):
                await self.page.evaluate('window.scrollBy(0, 1000)')
                await asyncio.sleep(1)

            # è§£æç¬”è®°åˆ—è¡¨
            notes = await self._parse_search_results(count)

            logger.info(f"æœç´¢ '{keyword}' æ‰¾åˆ° {len(notes)} æ¡ç¬”è®°")
            return notes

        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            return []

    async def _parse_search_results(self, count: int) -> list[XhsNote]:
        """
        è§£ææœç´¢ç»“æœé¡µé¢

        Args:
            count: æœ€å¤§è·å–æ•°é‡

        Returns:
            ç¬”è®°åˆ—è¡¨
        """
        notes = []

        try:
            # ç­‰å¾…ç¬”è®°å¡ç‰‡åŠ è½½
            await self.page.wait_for_selector('section.note-item, div[class*="note-item"]', timeout=10000)

            # è·å–æ‰€æœ‰ç¬”è®°å¡ç‰‡
            note_elements = await self.page.query_selector_all('section.note-item, div[class*="note-item"]')

            for element in note_elements[:count]:
                try:
                    note = await self._parse_note_card(element)
                    if note:
                        notes.append(note)
                except Exception as e:
                    logger.debug(f"è§£æç¬”è®°å¡ç‰‡å¤±è´¥: {e}")
                    continue

        except Exception as e:
            logger.error(f"è§£ææœç´¢ç»“æœå¤±è´¥: {e}")

        return notes

    async def _parse_note_card(self, element) -> Optional[XhsNote]:
        """
        è§£æå•ä¸ªç¬”è®°å¡ç‰‡

        Args:
            element: ç¬”è®°å¡ç‰‡å…ƒç´ 

        Returns:
            XhsNote å¯¹è±¡
        """
        try:
            # è·å–é“¾æ¥å’Œ ID
            link_elem = await element.query_selector('a[href*="/explore/"], a[href*="/search_result/"]')
            if not link_elem:
                link_elem = await element.query_selector('a')

            href = await link_elem.get_attribute('href') if link_elem else ""
            note_id = ""
            if '/explore/' in href:
                note_id = href.split('/explore/')[-1].split('?')[0]
            elif '/search_result/' in href:
                note_id = href.split('/')[-1].split('?')[0]

            # è·å–æ ‡é¢˜
            title_elem = await element.query_selector('span.title, div[class*="title"], a.title')
            title = await title_elem.inner_text() if title_elem else ""

            # è·å–ä½œè€…
            author_elem = await element.query_selector('span.name, div[class*="author"], span[class*="name"]')
            author = await author_elem.inner_text() if author_elem else ""

            # è·å–ç‚¹èµæ•°
            likes_elem = await element.query_selector('span.count, span[class*="like"], span[class*="count"]')
            likes_text = await likes_elem.inner_text() if likes_elem else "0"
            likes = self._parse_count(likes_text)

            # è·å–å°é¢å›¾
            img_elem = await element.query_selector('img')
            cover_url = await img_elem.get_attribute('src') if img_elem else ""

            if not note_id and not title:
                return None

            return XhsNote(
                note_id=note_id or f"unknown_{random.randint(1000, 9999)}",
                title=title.strip() if title else "æ— æ ‡é¢˜",
                desc="",  # åˆ—è¡¨é¡µæ— å®Œæ•´æè¿°
                author=author.strip() if author else "æœªçŸ¥ä½œè€…",
                likes=likes,
                images=[cover_url] if cover_url else [],
                url=f"{self.BASE_URL}/explore/{note_id}" if note_id else "",
            )

        except Exception as e:
            logger.debug(f"è§£æç¬”è®°å¡ç‰‡å¼‚å¸¸: {e}")
            return None

    def _parse_count(self, count_str: str) -> int:
        """è§£ææ•°é‡å­—ç¬¦ä¸²ï¼ˆå¦‚ '1.2ä¸‡'ï¼‰"""
        if not count_str:
            return 0

        count_str = str(count_str).strip()

        try:
            # ç§»é™¤éæ•°å­—å­—ç¬¦ï¼ˆä¿ç•™æ•°å­—ã€å°æ•°ç‚¹ã€ä¸‡/wï¼‰
            count_str = re.sub(r'[^\d.ä¸‡wW]', '', count_str)

            if 'ä¸‡' in count_str or 'w' in count_str.lower():
                num = float(count_str.replace('ä¸‡', '').replace('w', '').replace('W', ''))
                return int(num * 10000)
            elif count_str:
                return int(float(count_str))
            else:
                return 0
        except Exception:
            return 0

    async def get_note_detail(self, note_id: str) -> Optional[XhsNote]:
        """
        è·å–ç¬”è®°è¯¦æƒ…

        Args:
            note_id: ç¬”è®° ID

        Returns:
            ç¬”è®°è¯¦æƒ…
        """
        if not self.page:
            await self._init_browser()

        try:
            url = f"{self.BASE_URL}/explore/{note_id}"
            await self.page.goto(url, wait_until='networkidle', timeout=30000)
            await asyncio.sleep(2)

            # è§£æè¯¦æƒ…é¡µ
            # æ ‡é¢˜
            title_elem = await self.page.query_selector('div#detail-title, h1[class*="title"]')
            title = await title_elem.inner_text() if title_elem else ""

            # æ­£æ–‡
            desc_elem = await self.page.query_selector('div#detail-desc, div[class*="desc"], div[class*="content"]')
            desc = await desc_elem.inner_text() if desc_elem else ""

            # ä½œè€…
            author_elem = await self.page.query_selector('span.username, a[class*="name"]')
            author = await author_elem.inner_text() if author_elem else ""

            # äº’åŠ¨æ•°æ®
            likes_elem = await self.page.query_selector('span[class*="like"] span, span.count')
            likes = self._parse_count(await likes_elem.inner_text() if likes_elem else "0")

            # å›¾ç‰‡åˆ—è¡¨
            images = []
            img_elems = await self.page.query_selector_all('div[class*="swiper"] img, div[class*="carousel"] img')
            for img in img_elems:
                src = await img.get_attribute('src')
                if src:
                    images.append(src)

            # æ ‡ç­¾
            tags = []
            tag_elems = await self.page.query_selector_all('a[href*="/search_result?keyword="]')
            for tag in tag_elems:
                tag_text = await tag.inner_text()
                if tag_text and tag_text.startswith('#'):
                    tags.append(tag_text[1:])

            return XhsNote(
                note_id=note_id,
                title=title.strip(),
                desc=desc.strip(),
                author=author.strip(),
                likes=likes,
                images=images,
                tags=tags,
                url=url,
            )

        except Exception as e:
            logger.error(f"è·å–ç¬”è®°è¯¦æƒ…å¤±è´¥: {e}")
            return None

    async def get_hot_notes(
        self,
        keyword: str,
        count: int = 10,
    ) -> list[XhsNote]:
        """
        è·å–çƒ­é—¨ç¬”è®°

        Args:
            keyword: æœç´¢å…³é”®è¯
            count: è·å–æ•°é‡

        Returns:
            çƒ­é—¨ç¬”è®°åˆ—è¡¨
        """
        logger.info(f"å¼€å§‹è·å– '{keyword}' ç›¸å…³çƒ­é—¨ç¬”è®°...")

        notes = await self.search(keyword, count=count * 2)

        if not notes:
            logger.warning(f"æœªæ‰¾åˆ° '{keyword}' ç›¸å…³ç¬”è®°")
            return []

        # æŒ‰çƒ­åº¦æ’åº
        notes.sort(key=lambda x: x.likes + x.collects + x.comments, reverse=True)

        hot_notes = notes[:count]
        logger.info(f"è·å–åˆ° {len(hot_notes)} æ¡çƒ­é—¨ç¬”è®°")

        return hot_notes

    async def generate_article(
        self,
        notes: list[XhsNote],
        style: str = "ç§è‰",
    ) -> str:
        """
        åŸºäºç¬”è®°å†…å®¹ç”Ÿæˆå…¬ä¼—å·æ–‡ç« 

        Args:
            notes: ç¬”è®°åˆ—è¡¨
            style: æ–‡ç« é£æ ¼

        Returns:
            ç”Ÿæˆçš„æ–‡ç« å†…å®¹
        """
        if not notes:
            return ""

        # å‡†å¤‡ç¬”è®°æ‘˜è¦
        notes_summary = []
        for i, note in enumerate(notes, 1):
            summary = f"""
ã€ç¬”è®°{i}ã€‘
æ ‡é¢˜ï¼š{note.title}
ä½œè€…ï¼š{note.author}
å†…å®¹ï¼š{note.desc[:500] if note.desc else 'ï¼ˆæ— è¯¦ç»†å†…å®¹ï¼‰'}
ç‚¹èµï¼š{note.likes} | æ”¶è—ï¼š{note.collects} | è¯„è®ºï¼š{note.comments}
æ ‡ç­¾ï¼š{', '.join(note.tags) if note.tags else 'æ— '}
"""
            notes_summary.append(summary)

        # ç”Ÿæˆæ–‡ç« 
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å…¬ä¼—å·å†…å®¹åˆ›ä½œè€…ï¼Œæ“…é•¿å°†å°çº¢ä¹¦çƒ­é—¨å†…å®¹æ”¹ç¼–ä¸ºå…¬ä¼—å·æ–‡ç« ã€‚

è¯·æ ¹æ®ä»¥ä¸‹å°çº¢ä¹¦çƒ­é—¨ç¬”è®°ï¼Œç”Ÿæˆä¸€ç¯‡{style}é£æ ¼çš„å…¬ä¼—å·æ–‡ç« ã€‚

## å°çº¢ä¹¦çƒ­é—¨ç¬”è®°

{''.join(notes_summary)}

## å†™ä½œè¦æ±‚

1. **æ ‡é¢˜**ï¼šå¸å¼•äººä½†ä¸æ ‡é¢˜å…šï¼Œä½“ç°ä»·å€¼
2. **å¼€å¤´**ï¼šå¿«é€Ÿåˆ‡å…¥ä¸»é¢˜ï¼Œå¼•å‘å…±é¸£
3. **æ­£æ–‡**ï¼š
   - æ•´åˆå¤šä¸ªç¬”è®°çš„æ ¸å¿ƒè§‚ç‚¹
   - åŠ å…¥ä½ çš„ä¸“ä¸šåˆ†æå’Œè§è§£
   - ä¿æŒå£è¯­åŒ–ã€æœ‰ç½‘æ„Ÿ
   - é¿å…ç›´æ¥å¤åˆ¶åŸæ–‡
4. **ç»“å°¾**ï¼šå¼•å¯¼äº’åŠ¨ï¼Œé‚€è¯·è¯»è€…ç•™è¨€
5. **å­—æ•°**ï¼š1500-2500 å­—

## æ ¼å¼è¦æ±‚

```
# æ ‡é¢˜

æ­£æ–‡å†…å®¹...

---
ä½ è§‰å¾—è¿™äº›xxxæ€ä¹ˆæ ·ï¼Ÿæ¬¢è¿åœ¨è¯„è®ºåŒºåˆ†äº«ä½ çš„çœ‹æ³•~
```

è¯·ç›´æ¥è¾“å‡ºæ–‡ç« å†…å®¹ï¼š
"""

        try:
            ai_client = get_ai_client()
            response = ai_client.generate_sync(prompt)
            article = response.text.strip()

            # æ¸…ç† markdown ä»£ç å—æ ‡è®°
            if article.startswith("```"):
                article = re.sub(r'^```\w*\n?', '', article)
                article = re.sub(r'\n?```$', '', article)

            logger.info(f"æ–‡ç« ç”Ÿæˆå®Œæˆï¼Œå­—æ•°ï¼š{len(article)}")
            return article

        except Exception as e:
            logger.error(f"æ–‡ç« ç”Ÿæˆå¤±è´¥: {e}")
            return ""

    async def run(
        self,
        keyword: str = "AIå·¥å…·",
        count: int = 5,
        style: str = "ç§è‰",
    ) -> dict:
        """
        å®Œæ•´æ‰§è¡Œæµç¨‹

        Args:
            keyword: æœç´¢å…³é”®è¯
            count: é‡‡é›†ç¬”è®°æ•°é‡
            style: æ–‡ç« é£æ ¼

        Returns:
            æ‰§è¡Œç»“æœ
        """
        logger.info(f"å¼€å§‹å°çº¢ä¹¦é‡‡é›†ä»»åŠ¡: å…³é”®è¯={keyword}, æ•°é‡={count}, é£æ ¼={style}")

        if not self.is_logged_in():
            return {
                "success": False,
                "error": "æœªé…ç½®å°çº¢ä¹¦ Cookieï¼Œè¯·åœ¨ config.yaml ä¸­é…ç½® xiaohongshu.cookies",
                "notes": [],
                "article": "",
            }

        try:
            # 1. è·å–çƒ­é—¨ç¬”è®°
            notes = await self.get_hot_notes(keyword, count)

            if not notes:
                return {
                    "success": False,
                    "error": f"æœªæ‰¾åˆ° '{keyword}' ç›¸å…³ç¬”è®°",
                    "notes": [],
                    "article": "",
                }

            # 2. è·å–éƒ¨åˆ†ç¬”è®°çš„è¯¦æƒ…ï¼ˆä¸°å¯Œå†…å®¹ï¼‰
            for i, note in enumerate(notes[:3]):  # åªè·å–å‰3æ¡çš„è¯¦æƒ…
                if note.note_id and note.note_id != "unknown":
                    detail = await self.get_note_detail(note.note_id)
                    if detail and detail.desc:
                        notes[i].desc = detail.desc
                        notes[i].tags = detail.tags
                    await asyncio.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«

            # 3. ç”Ÿæˆæ–‡ç« 
            article = await self.generate_article(notes, style)

            if not article:
                return {
                    "success": False,
                    "error": "æ–‡ç« ç”Ÿæˆå¤±è´¥",
                    "notes": [n.to_dict() for n in notes],
                    "article": "",
                }

            # 4. æå–æ ‡é¢˜å¹¶åˆ›å»ºæ–‡ç« ç›®å½•
            article_lines = article.split('\n')
            title = keyword
            for line in article_lines:
                if line.startswith('#'):
                    title = line.replace('#', '').strip()[:30]
                    break

            article_dir = create_article_dir(title)
            logger.info(f"æ–‡ç« ç›®å½•å·²åˆ›å»º: {article_dir}")

            # 5. ä¿å­˜æ–‡ç« 
            article_path = get_article_file_path(article_dir, "article.md")
            article_path.write_text(article, encoding="utf-8")
            logger.info(f"æ–‡ç« å·²ä¿å­˜: {article_path}")

            # 5. ä¿å­˜å…ƒæ•°æ®
            metadata = {
                "title": title,
                "keyword": keyword,
                "style": style,
                "date": get_today_str(),
                "notes_count": len(notes),
                "notes": [n.to_dict() for n in notes],
            }
            metadata_path = get_article_file_path(article_dir, "metadata.json")
            metadata_path.write_text(
                json.dumps(metadata, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )
            logger.info(f"å…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}")

            return {
                "success": True,
                "error": None,
                "notes": [n.to_dict() for n in notes],
                "article": article,
                "article_title": title,
                "article_content": article,
                "keyword": keyword,
                "style": style,
                "output_path": str(article_dir),
            }

        except Exception as e:
            logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "notes": [],
                "article": "",
            }

        finally:
            await self.close()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å‘½ä»¤è¡Œå…¥å£
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description="å°çº¢ä¹¦æµè§ˆå™¨é‡‡é›†å™¨")
    parser.add_argument("keyword", nargs="?", default="AIå·¥å…·", help="æœç´¢å…³é”®è¯")
    parser.add_argument("-n", "--count", type=int, default=5, help="é‡‡é›†æ•°é‡")
    parser.add_argument("-s", "--style", default="ç§è‰", help="æ–‡ç« é£æ ¼")
    args = parser.parse_args()

    browser = XiaohongshuBrowser()
    result = await browser.run(args.keyword, args.count, args.style)

    if result["success"]:
        print(f"\n{'=' * 50}")
        print("âœ… é‡‡é›†æˆåŠŸï¼")
        print(f"{'=' * 50}\n")
        print(result["article"][:500] + "...\n")

        print(f"ğŸ“ æ–‡ç« ç›®å½•: {result.get('output_path', 'N/A')}")
    else:
        print(f"\nâŒ é‡‡é›†å¤±è´¥: {result['error']}")


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
