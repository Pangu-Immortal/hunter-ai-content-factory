"""
Hunter AI å†…å®¹å·¥å‚ - å°çº¢ä¹¦é‡‡é›†æ¨¡å—

åŠŸèƒ½ï¼š
- åŸºäº httpx + Cookie é‡‡é›†å°çº¢ä¹¦ç¬”è®°
- æœç´¢æŒ‡å®šå…³é”®è¯çš„ç¬”è®°
- è·å–çƒ­é—¨ç¬”è®°åˆ—è¡¨
- AI ç”Ÿæˆç§è‰/æµ‹è¯„æ–‡ç« 

ä½¿ç”¨æ–¹æ³•ï¼š
    from src.intel.xiaohongshu_hunter import XiaohongshuHunter

    hunter = XiaohongshuHunter()
    notes = await hunter.get_hot_notes("AIå·¥å…·")
    article = await hunter.generate_article(notes)

Cookie è·å–æ–¹æ³•ï¼š
    1. æµè§ˆå™¨ç™»å½•å°çº¢ä¹¦ (https://www.xiaohongshu.com)
    2. F12 æ‰“å¼€å¼€å‘è€…å·¥å…· â†’ Application â†’ Cookies
    3. å¤åˆ¶æ‰€æœ‰ Cookie åˆ° config.yaml çš„ xiaohongshu.cookies å­—æ®µ

GitHub: https://github.com/Pangu-Immortal/hunter-ai-content-factory
Author: Pangu-Immortal
"""

import json
import re
import hashlib
import time
import random
from pathlib import Path
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional
from urllib.parse import urlencode

import httpx

from src.config import settings, ROOT_DIR
from src.utils.logger import get_logger
from src.utils.ai_client import get_ai_client
from src.intel.utils import create_article_dir, get_article_file_path, get_today_str

logger = get_logger("hunter.intel.xiaohongshu")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ•°æ®æ¨¡å‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class XhsNote:
    """å°çº¢ä¹¦ç¬”è®°æ•°æ®"""
    note_id: str                          # ç¬”è®° ID
    title: str                            # æ ‡é¢˜
    desc: str                             # æè¿°/æ­£æ–‡
    author: str                           # ä½œè€…æ˜µç§°
    author_id: str                        # ä½œè€… ID
    likes: int = 0                        # ç‚¹èµæ•°
    collects: int = 0                     # æ”¶è—æ•°
    comments: int = 0                     # è¯„è®ºæ•°
    images: list[str] = field(default_factory=list)  # å›¾ç‰‡åˆ—è¡¨
    tags: list[str] = field(default_factory=list)    # æ ‡ç­¾åˆ—è¡¨
    url: str = ""                         # ç¬”è®°é“¾æ¥
    created_at: Optional[datetime] = None # å‘å¸ƒæ—¶é—´

    def to_dict(self) -> dict:
        """è½¬ä¸ºå­—å…¸"""
        return {
            "note_id": self.note_id,
            "title": self.title,
            "desc": self.desc,
            "author": self.author,
            "author_id": self.author_id,
            "likes": self.likes,
            "collects": self.collects,
            "comments": self.comments,
            "images": self.images,
            "tags": self.tags,
            "url": self.url,
            "created_at": self.created_at.isoformat() if self.created_at else None,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å°çº¢ä¹¦é‡‡é›†å™¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class XiaohongshuHunter:
    """
    å°çº¢ä¹¦é‡‡é›†å™¨ - åŸºäº httpx + Cookie

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æœç´¢ç¬”è®° - æŒ‰å…³é”®è¯æœç´¢
    2. è·å–çƒ­é—¨ç¬”è®° - è·å–æŒ‡å®šè¯é¢˜çš„çƒ­é—¨å†…å®¹
    3. AI ç”Ÿæˆæ–‡ç«  - åŸºäºé‡‡é›†å†…å®¹ç”Ÿæˆå…¬ä¼—å·æ–‡ç« 
    """

    # API åŸºç¡€é…ç½®
    BASE_URL = "https://edith.xiaohongshu.com"
    WEB_URL = "https://www.xiaohongshu.com"

    # è¯·æ±‚å¤´æ¨¡æ¿
    DEFAULT_HEADERS = {
        "accept": "application/json, text/plain, */*",
        "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
        "content-type": "application/json;charset=UTF-8",
        "origin": "https://www.xiaohongshu.com",
        "referer": "https://www.xiaohongshu.com/",
        "user-agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    }

    def __init__(self):
        """åˆå§‹åŒ–é‡‡é›†å™¨"""
        self.cookies = self._load_cookies()
        self.client: Optional[httpx.AsyncClient] = None

    def _load_cookies(self) -> dict:
        """
        åŠ è½½ Cookie

        ä¼˜å…ˆçº§ï¼š
        1. config.yaml ä¸­çš„ xiaohongshu.cookies
        2. data/auth/xiaohongshu_cookies.json æ–‡ä»¶
        """
        # ä»é…ç½®æ–‡ä»¶åŠ è½½
        if hasattr(settings, 'xiaohongshu') and settings.xiaohongshu.cookies:
            cookie_str = settings.xiaohongshu.cookies
            return self._parse_cookie_string(cookie_str)

        # ä»æ–‡ä»¶åŠ è½½
        cookie_file = ROOT_DIR / "data" / "auth" / "xiaohongshu_cookies.json"
        if cookie_file.exists():
            try:
                with open(cookie_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"è¯»å– Cookie æ–‡ä»¶å¤±è´¥: {e}")

        return {}

    def _parse_cookie_string(self, cookie_str: str) -> dict:
        """è§£æ Cookie å­—ç¬¦ä¸²ä¸ºå­—å…¸"""
        cookies = {}
        for item in cookie_str.split(';'):
            item = item.strip()
            if '=' in item:
                key, value = item.split('=', 1)
                cookies[key.strip()] = value.strip()
        return cookies

    def save_cookies(self, cookies: dict) -> None:
        """ä¿å­˜ Cookie åˆ°æ–‡ä»¶"""
        cookie_dir = ROOT_DIR / "data" / "auth"
        cookie_dir.mkdir(parents=True, exist_ok=True)

        cookie_file = cookie_dir / "xiaohongshu_cookies.json"
        with open(cookie_file, 'w', encoding='utf-8') as f:
            json.dump(cookies, f, ensure_ascii=False, indent=2)

        logger.info(f"Cookie å·²ä¿å­˜åˆ° {cookie_file}")

    def is_logged_in(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²ç™»å½•ï¼ˆCookie æ˜¯å¦æœ‰æ•ˆï¼‰"""
        required_keys = ['web_session', 'a1']
        return all(key in self.cookies for key in required_keys)

    async def _get_client(self) -> httpx.AsyncClient:
        """è·å– HTTP å®¢æˆ·ç«¯"""
        if self.client is None:
            self.client = httpx.AsyncClient(
                headers=self.DEFAULT_HEADERS,
                cookies=self.cookies,
                timeout=30.0,
                follow_redirects=True,
            )
        return self.client

    async def close(self) -> None:
        """å…³é—­å®¢æˆ·ç«¯"""
        if self.client:
            await self.client.aclose()
            self.client = None

    def _generate_x_s(self, url: str, data: Optional[dict] = None) -> str:
        """
        ç”Ÿæˆ X-s ç­¾å

        æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…å°çº¢ä¹¦çš„ç­¾åç®—æ³•æ›´å¤æ‚
        å¦‚æœé‡åˆ°ç­¾åéªŒè¯é—®é¢˜ï¼Œå¯èƒ½éœ€è¦æ›´æ–°æ­¤æ–¹æ³•
        """
        # ç®€åŒ–ç­¾åï¼šæ—¶é—´æˆ³ + éšæœºæ•°
        timestamp = int(time.time() * 1000)
        random_str = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=8))
        sign_str = f"{timestamp}{random_str}{url}"

        if data:
            sign_str += json.dumps(data, separators=(',', ':'), ensure_ascii=False)

        return hashlib.md5(sign_str.encode()).hexdigest()

    async def search(
        self,
        keyword: str,
        page: int = 1,
        page_size: int = 20,
        sort: str = "general",  # general: ç»¼åˆ, time_descending: æœ€æ–°, popularity_descending: æœ€çƒ­
    ) -> list[XhsNote]:
        """
        æœç´¢å°çº¢ä¹¦ç¬”è®°

        Args:
            keyword: æœç´¢å…³é”®è¯
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡
            sort: æ’åºæ–¹å¼

        Returns:
            ç¬”è®°åˆ—è¡¨
        """
        if not self.is_logged_in():
            logger.error("æœªç™»å½•ï¼Œè¯·å…ˆé…ç½® Cookie")
            return []

        client = await self._get_client()

        # æ„å»ºæœç´¢è¯·æ±‚
        api_url = "/api/sns/web/v1/search/notes"
        params = {
            "keyword": keyword,
            "page": page,
            "page_size": page_size,
            "sort": sort,
            "note_type": 0,  # 0: å…¨éƒ¨, 1: è§†é¢‘, 2: å›¾æ–‡
        }

        try:
            # æ·»åŠ ç­¾å
            headers = {
                "x-s": self._generate_x_s(api_url, params),
                "x-t": str(int(time.time() * 1000)),
            }

            response = await client.post(
                f"{self.BASE_URL}{api_url}",
                json=params,
                headers=headers,
            )

            if response.status_code != 200:
                logger.error(f"æœç´¢è¯·æ±‚å¤±è´¥: {response.status_code}")
                return []

            data = response.json()

            if data.get("success") is False:
                logger.error(f"æœç´¢å¤±è´¥: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                return []

            # è§£æç»“æœ
            notes = []
            items = data.get("data", {}).get("items", [])

            for item in items:
                note_card = item.get("note_card", {})
                user = note_card.get("user", {})

                note = XhsNote(
                    note_id=item.get("id", ""),
                    title=note_card.get("display_title", ""),
                    desc=note_card.get("desc", ""),
                    author=user.get("nickname", ""),
                    author_id=user.get("user_id", ""),
                    likes=note_card.get("interact_info", {}).get("liked_count", 0),
                    collects=note_card.get("interact_info", {}).get("collected_count", 0),
                    comments=note_card.get("interact_info", {}).get("comment_count", 0),
                    url=f"{self.WEB_URL}/explore/{item.get('id', '')}",
                )

                # æå–å›¾ç‰‡
                if "image_list" in note_card:
                    note.images = [
                        img.get("url_default", "") or img.get("url", "")
                        for img in note_card.get("image_list", [])
                    ]

                # æå–æ ‡ç­¾
                if "tag_list" in note_card:
                    note.tags = [tag.get("name", "") for tag in note_card.get("tag_list", [])]

                notes.append(note)

            logger.info(f"æœç´¢ '{keyword}' æ‰¾åˆ° {len(notes)} æ¡ç¬”è®°")
            return notes

        except Exception as e:
            logger.error(f"æœç´¢å¼‚å¸¸: {e}")
            return []

    async def get_note_detail(self, note_id: str) -> Optional[XhsNote]:
        """
        è·å–ç¬”è®°è¯¦æƒ…

        Args:
            note_id: ç¬”è®° ID

        Returns:
            ç¬”è®°è¯¦æƒ…
        """
        if not self.is_logged_in():
            logger.error("æœªç™»å½•ï¼Œè¯·å…ˆé…ç½® Cookie")
            return None

        client = await self._get_client()

        api_url = "/api/sns/web/v1/feed"
        params = {
            "source_note_id": note_id,
        }

        try:
            headers = {
                "x-s": self._generate_x_s(api_url, params),
                "x-t": str(int(time.time() * 1000)),
            }

            response = await client.post(
                f"{self.BASE_URL}{api_url}",
                json=params,
                headers=headers,
            )

            if response.status_code != 200:
                logger.error(f"è·å–ç¬”è®°è¯¦æƒ…å¤±è´¥: {response.status_code}")
                return None

            data = response.json()

            if data.get("success") is False:
                logger.error(f"è·å–ç¬”è®°è¯¦æƒ…å¤±è´¥: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                return None

            # è§£æè¯¦æƒ…
            items = data.get("data", {}).get("items", [])
            if not items:
                return None

            note_data = items[0].get("note_card", {})
            user = note_data.get("user", {})
            interact = note_data.get("interact_info", {})

            note = XhsNote(
                note_id=note_id,
                title=note_data.get("title", ""),
                desc=note_data.get("desc", ""),
                author=user.get("nickname", ""),
                author_id=user.get("user_id", ""),
                likes=self._parse_count(interact.get("liked_count", "0")),
                collects=self._parse_count(interact.get("collected_count", "0")),
                comments=self._parse_count(interact.get("comment_count", "0")),
                url=f"{self.WEB_URL}/explore/{note_id}",
            )

            # æå–å›¾ç‰‡
            if "image_list" in note_data:
                note.images = [
                    img.get("url_default", "") or img.get("info_list", [{}])[0].get("url", "")
                    for img in note_data.get("image_list", [])
                ]

            # æå–æ ‡ç­¾
            if "tag_list" in note_data:
                note.tags = [tag.get("name", "") for tag in note_data.get("tag_list", [])]

            # å‘å¸ƒæ—¶é—´
            if "time" in note_data:
                try:
                    note.created_at = datetime.fromtimestamp(note_data["time"] / 1000)
                except Exception:
                    pass

            return note

        except Exception as e:
            logger.error(f"è·å–ç¬”è®°è¯¦æƒ…å¼‚å¸¸: {e}")
            return None

    def _parse_count(self, count_str: str) -> int:
        """è§£ææ•°é‡å­—ç¬¦ä¸²ï¼ˆå¦‚ '1.2ä¸‡'ï¼‰"""
        if isinstance(count_str, int):
            return count_str

        count_str = str(count_str).strip()
        if not count_str:
            return 0

        try:
            if 'ä¸‡' in count_str:
                return int(float(count_str.replace('ä¸‡', '')) * 10000)
            elif 'w' in count_str.lower():
                return int(float(count_str.lower().replace('w', '')) * 10000)
            else:
                return int(count_str)
        except Exception:
            return 0

    async def get_hot_notes(
        self,
        keyword: str,
        count: int = 10,
    ) -> list[XhsNote]:
        """
        è·å–çƒ­é—¨ç¬”è®°

        Args:
            keyword: æœç´¢å…³é”®è¯
            count: è·å–æ•°é‡

        Returns:
            çƒ­é—¨ç¬”è®°åˆ—è¡¨ï¼ˆæŒ‰çƒ­åº¦æ’åºï¼‰
        """
        logger.info(f"å¼€å§‹è·å– '{keyword}' ç›¸å…³çƒ­é—¨ç¬”è®°...")

        # æœç´¢ç¬”è®°
        notes = await self.search(keyword, page_size=min(count * 2, 40), sort="popularity_descending")

        if not notes:
            logger.warning(f"æœªæ‰¾åˆ° '{keyword}' ç›¸å…³ç¬”è®°")
            return []

        # æŒ‰çƒ­åº¦æ’åºï¼ˆç‚¹èµ + æ”¶è— + è¯„è®ºï¼‰
        notes.sort(key=lambda x: x.likes + x.collects + x.comments, reverse=True)

        # å–å‰ N æ¡
        hot_notes = notes[:count]

        logger.info(f"è·å–åˆ° {len(hot_notes)} æ¡çƒ­é—¨ç¬”è®°")
        return hot_notes

    async def generate_article(
        self,
        notes: list[XhsNote],
        style: str = "ç§è‰",  # ç§è‰ / æµ‹è¯„ / ç›˜ç‚¹
    ) -> str:
        """
        åŸºäºç¬”è®°å†…å®¹ç”Ÿæˆå…¬ä¼—å·æ–‡ç« 

        Args:
            notes: ç¬”è®°åˆ—è¡¨
            style: æ–‡ç« é£æ ¼

        Returns:
            ç”Ÿæˆçš„æ–‡ç« å†…å®¹
        """
        if not notes:
            return ""

        # å‡†å¤‡ç¬”è®°æ‘˜è¦
        notes_summary = []
        for i, note in enumerate(notes, 1):
            summary = f"""
ã€ç¬”è®°{i}ã€‘
æ ‡é¢˜ï¼š{note.title}
ä½œè€…ï¼š{note.author}
å†…å®¹ï¼š{note.desc[:500]}...
ç‚¹èµï¼š{note.likes} | æ”¶è—ï¼š{note.collects} | è¯„è®ºï¼š{note.comments}
æ ‡ç­¾ï¼š{', '.join(note.tags) if note.tags else 'æ— '}
"""
            notes_summary.append(summary)

        # ç”Ÿæˆæ–‡ç« 
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å…¬ä¼—å·å†…å®¹åˆ›ä½œè€…ï¼Œæ“…é•¿å°†å°çº¢ä¹¦çƒ­é—¨å†…å®¹æ”¹ç¼–ä¸ºå…¬ä¼—å·æ–‡ç« ã€‚

è¯·æ ¹æ®ä»¥ä¸‹å°çº¢ä¹¦çƒ­é—¨ç¬”è®°ï¼Œç”Ÿæˆä¸€ç¯‡{style}é£æ ¼çš„å…¬ä¼—å·æ–‡ç« ã€‚

## å°çº¢ä¹¦çƒ­é—¨ç¬”è®°

{''.join(notes_summary)}

## å†™ä½œè¦æ±‚

1. **æ ‡é¢˜**ï¼šå¸å¼•äººä½†ä¸æ ‡é¢˜å…šï¼Œä½“ç°ä»·å€¼
2. **å¼€å¤´**ï¼šå¿«é€Ÿåˆ‡å…¥ä¸»é¢˜ï¼Œå¼•å‘å…±é¸£
3. **æ­£æ–‡**ï¼š
   - æ•´åˆå¤šä¸ªç¬”è®°çš„æ ¸å¿ƒè§‚ç‚¹
   - åŠ å…¥ä½ çš„ä¸“ä¸šåˆ†æå’Œè§è§£
   - ä¿æŒå£è¯­åŒ–ã€æœ‰ç½‘æ„Ÿ
   - é¿å…ç›´æ¥å¤åˆ¶åŸæ–‡
4. **ç»“å°¾**ï¼šå¼•å¯¼äº’åŠ¨ï¼Œé‚€è¯·è¯»è€…ç•™è¨€
5. **å­—æ•°**ï¼š1500-2500 å­—

## æ ¼å¼è¦æ±‚

```
# æ ‡é¢˜

æ­£æ–‡å†…å®¹...

---
ä½ è§‰å¾—è¿™äº›xxxæ€ä¹ˆæ ·ï¼Ÿæ¬¢è¿åœ¨è¯„è®ºåŒºåˆ†äº«ä½ çš„çœ‹æ³•~
```

è¯·ç›´æ¥è¾“å‡ºæ–‡ç« å†…å®¹ï¼š
"""

        try:
            from src.utils.ai_client import get_ai_client

            ai_client = get_ai_client()
            response = ai_client.generate_sync(prompt)
            article = response.text.strip()

            # æ¸…ç† markdown ä»£ç å—æ ‡è®°
            if article.startswith("```"):
                article = re.sub(r'^```\w*\n?', '', article)
                article = re.sub(r'\n?```$', '', article)

            logger.info(f"æ–‡ç« ç”Ÿæˆå®Œæˆï¼Œå­—æ•°ï¼š{len(article)}")
            return article

        except Exception as e:
            logger.error(f"æ–‡ç« ç”Ÿæˆå¤±è´¥: {e}")
            return ""

    async def run(
        self,
        keyword: str = "AIå·¥å…·",
        count: int = 5,
        style: str = "ç§è‰",
    ) -> dict:
        """
        å®Œæ•´æ‰§è¡Œæµç¨‹

        Args:
            keyword: æœç´¢å…³é”®è¯
            count: é‡‡é›†ç¬”è®°æ•°é‡
            style: æ–‡ç« é£æ ¼

        Returns:
            æ‰§è¡Œç»“æœ
        """
        logger.info(f"å¼€å§‹å°çº¢ä¹¦é‡‡é›†ä»»åŠ¡: å…³é”®è¯={keyword}, æ•°é‡={count}, é£æ ¼={style}")

        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        if not self.is_logged_in():
            return {
                "success": False,
                "error": "æœªé…ç½®å°çº¢ä¹¦ Cookieï¼Œè¯·åœ¨ config.yaml ä¸­é…ç½® xiaohongshu.cookies",
                "notes": [],
                "article": "",
            }

        try:
            # 1. è·å–çƒ­é—¨ç¬”è®°
            notes = await self.get_hot_notes(keyword, count)

            if not notes:
                return {
                    "success": False,
                    "error": f"æœªæ‰¾åˆ° '{keyword}' ç›¸å…³ç¬”è®°",
                    "notes": [],
                    "article": "",
                }

            # 2. ç”Ÿæˆæ–‡ç« 
            article = await self.generate_article(notes, style)

            if not article:
                return {
                    "success": False,
                    "error": "æ–‡ç« ç”Ÿæˆå¤±è´¥",
                    "notes": [n.to_dict() for n in notes],
                    "article": "",
                }

            # 3. æå–æ ‡é¢˜å¹¶åˆ›å»ºæ–‡ç« ç›®å½•
            article_lines = article.split('\n')
            title = keyword  # é»˜è®¤ä½¿ç”¨å…³é”®è¯
            for line in article_lines:
                if line.startswith('#'):
                    title = line.replace('#', '').strip()[:30]
                    break

            article_dir = create_article_dir(title)
            logger.info(f"æ–‡ç« ç›®å½•å·²åˆ›å»º: {article_dir}")

            # 4. ä¿å­˜æ–‡ç« 
            article_path = get_article_file_path(article_dir, "article.md")
            article_path.write_text(article, encoding="utf-8")
            logger.info(f"æ–‡ç« å·²ä¿å­˜: {article_path}")

            # 4. ä¿å­˜å…ƒæ•°æ®
            metadata = {
                "title": title,
                "keyword": keyword,
                "style": style,
                "date": get_today_str(),
                "notes_count": len(notes),
                "notes": [n.to_dict() for n in notes],
            }
            metadata_path = get_article_file_path(article_dir, "metadata.json")
            metadata_path.write_text(
                json.dumps(metadata, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )
            logger.info(f"å…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}")

            return {
                "success": True,
                "error": None,
                "notes": [n.to_dict() for n in notes],
                "article": article,
                "keyword": keyword,
                "style": style,
                "article_dir": str(article_dir),
            }

        except Exception as e:
            logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "notes": [],
                "article": "",
            }

        finally:
            await self.close()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å‘½ä»¤è¡Œå…¥å£
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description="å°çº¢ä¹¦é‡‡é›†å™¨")
    parser.add_argument("keyword", nargs="?", default="AIå·¥å…·", help="æœç´¢å…³é”®è¯")
    parser.add_argument("-n", "--count", type=int, default=5, help="é‡‡é›†æ•°é‡")
    parser.add_argument("-s", "--style", default="ç§è‰", help="æ–‡ç« é£æ ¼")
    args = parser.parse_args()

    hunter = XiaohongshuHunter()
    result = await hunter.run(args.keyword, args.count, args.style)

    if result["success"]:
        print(f"\n{'=' * 50}")
        print("âœ… é‡‡é›†æˆåŠŸï¼")
        print(f"{'=' * 50}\n")
        print(result["article"][:500] + "...\n")  # åªé¢„è§ˆå‰ 500 å­—

        # è¾“å‡ºä¿å­˜ä½ç½®
        print(f"ğŸ“ æ–‡ç« ç›®å½•: {result.get('article_dir', 'N/A')}")
    else:
        print(f"\nâŒ é‡‡é›†å¤±è´¥: {result['error']}")


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
